===========
Quick Start
===========

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 2
   :class: singlecol

Overview
--------

This guide shows you how to use the {+mkc+} to connect MongoDB to {+ak+}.

You perform the following actions:

- :ref:`Add a {+mkc+} source connector <kafka-quick-start-source-connector-section>`
- :ref:`Add a {+mkc+} sink connector <kafka-quick-start-sink-connector-section>`
- :ref:`Send the contents of a MongoDB document through your source and sink connector <kafka-quick-start-send-a-document>`

In this guide, you download and work in a containerized development environment. 
Follow the instructions in the :ref:`<kafka-quickstart-remove-the-pipeline>`
section to remove the environment.

Requirements
------------

.. include:: /includes/tutorials/pipeline-requirements.rst

Download the Sample Pipeline
----------------------------

.. include:: /includes/tutorials/get-pipeline.rst

Start the Pipeline
------------------

The sample pipeline consists of the following services running in
Docker containers:

- A MongoDB replica set
- An {+ak+} instance
- A Kafka Connect instance with the MongoDB Kafka Connector installed
- A Zookeeper instance (Zookeeper is a dependency of Apache Kafka) 

To download and run the sample pipeline, execute the following command from
within the tutorial directory:

.. code-block:: shell

   docker-compose -p quickstart up -d

.. include:: /includes/tutorials/download-note.rst

Add Connectors
--------------

You must add a connector to {+kc+} to transfer data between {+kc+} and
MongoDB. Add a **source connector** to transfer data from MongoDB 
to {+ak+}. Add a **sink connector** to transfer data from {+ak+} to MongoDB.

To add connectors in the sample pipeline, you first need to enter a shell
in your Docker environment using the following command:

.. code-block:: shell

   docker exec -it shell /bin/bash

Once you are in the shell you should see a prompt that looks like this:

.. code-block:: none
   :copyable: false   

   [MongoDB Kafka Connector Quick Start]

.. _kafka-quick-start-source-connector-section:

Add a Source Connector
~~~~~~~~~~~~~~~~~~~~~~

In the shell in your Docker environment, add a source connector using the {+kc+}
REST API. The following command adds a source connector and specifies the
following properties:

- The class {+kc+} uses to instantiate the connector
- The connection URI, database, and collection of the MongoDB replica set from
  which the connector reads data
- An aggregation pipeline that adds a field ``travel`` with the value
  ``"MongoDB Kafka Connector"`` to inserted documents the connector reads from MongoDB

.. code-block:: bash

   curl -X POST \
        -H "Content-Type: application/json" \
        --data '
        {"name": "mongo-source",
         "config": {
            "connector.class":"com.mongodb.kafka.connect.MongoSourceConnector",
            "connection.uri":"mongodb://mongo1:27017/?replicaSet=rs0",
            "database":"quickstart",
            "collection":"sampleData",
            "pipeline":"[{\"$match\": {\"operationType\": \"insert\"}}, {$addFields : {\"fullDocument.travel\":\"MongoDB Kafka Connector\"}}]"
            }
        }
        ' \
        http://connect:8083/connectors -w "\n"

.. note:: Why do I see the message 'Failed to connect'?

   It takes up to three minutes for the {+kc+} REST API to start. If
   you receive the following error, wait three minutes and run the preceding
   command again:

   .. code-block:: none
      :copyable: false
 
      ...
      curl: (7) Failed to connect to connect port 8083: Connection refused

To confirm that you added the source connector, run the following command:

.. code-block:: shell

   curl -X GET http://connect:8083/connectors

The command should output the names of the running connectors:

.. code-block:: none
   :copyable: false

   ["mongo-source"]

To learn more about source connector properties, see the
:doc:`{+mkc+} Source Connectors <source-connector>` guide.

To learn more about aggregation pipelines, see 
:manual:`Aggregation Pipelines </core/aggregation-pipeline/>` in the MongoDB manual.

.. _kafka-quick-start-sink-connector-section:

Add a Sink Connector
~~~~~~~~~~~~~~~~~~~~

In the shell in your Docker environment, add a sink connector using the {+kc+}
REST API. The following command adds a sink connector and specifies the
following properties:

- The class {+kc+} uses to instantiate the connector
- The connection URI, database, and collection of the MongoDB replica set to which
  the connector writes data
- The {+ak+} topic from which the connector reads data
- A change data capture handler for MongoDB change event documents

.. code-block:: bash

   curl -X POST \
        -H "Content-Type: application/json" \
        --data '
        {"name": "mongo-sink",
         "config": {
            "connector.class":"com.mongodb.kafka.connect.MongoSinkConnector",
            "connection.uri":"mongodb://mongo1:27017/?replicaSet=rs0",
            "database":"quickstart",
            "collection":"topicData",
            "topics":"quickstart.sampleData",
            "change.data.capture.handler": "com.mongodb.kafka.connect.sink.cdc.mongodb.ChangeStreamHandler"
            }
        }
        ' \
        http://connect:8083/connectors -w "\n"

To confirm that you added the source and sink connectors, run the following command:

.. code-block:: shell

    curl -X GET http://connect:8083/connectors

The command should output the names of the running connectors:

.. code-block:: none
    :copyable: false

    ["mongo-source", "mongo-sink"]

To learn more about sink connectors, see the
:doc:`{+mkc+} Sink Connectors <sink-connector>` guide.

To learn more about change data capture events, see the
:ref:`<sink-fundamentals-cdc-handler>` guide.

.. _kafka-quick-start-send-a-document:

Send the Contents of a Document through Your Connectors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To send the contents of a document through your connectors, you need
to write data into the MongoDB collection from which your source connector reads
data. To write data into your collection, enter the MongoDB shell from 
the shell in your Docker environment:

.. code-block:: shell

   mongosh mongodb://mongo1:27017/?replicaSet=rs0 

Once you are in the MongoDB shell, you should see a prompt that looks like this:

.. code-block:: shell
   :copyable: false

   rs0 [primary] test>

From within the MongoDB shell, insert a document into the ``sampleData``
collection of the ``quickstart`` database using the following commands:

.. code-block:: javascript

   use quickstart
   db.sampleData.insertOne({"hello":"world"})

After you insert a document into the ``sampleData`` collection, confirm that your
connectors processed the change. Check the contents of the ``topicData``
collection with the following command:

.. code-block:: javascript

   db.topicData.find()

You should see output that resembles the following:

.. code-block:: json
   :copyable: false

   [
       {
         _id: ObjectId(...),
         hello: 'world',
         travel: 'MongoDB Kafka Connector'
       }
   ]

Exit the MongoDB shell with the following command:

.. code-block:: shell

   exit

.. _kafka-quickstart-remove-the-pipeline:

Remove the Pipeline
-------------------

To conserve resources in your development environment, remove the sample pipeline.

Before you remove the sample pipeline, exit the shell in your Docker environment
by running the following command:

.. code-block:: shell

   exit

To remove the sample pipeline and free resources, run the shell command in one of
the following tabs:

.. tabs::

   .. tab:: Remove Containers and Images
      :tabid: remove-containers

      The following command removes the Docker containers and images related to
      the sample pipeline:
      
      .. code-block:: shell
      
         docker-compose -p quickstart down --rmi 'all'

      .. important:: Download the Pipeline Again
      
         If you remove the images, you must download
         {+pipeline-size+} of files to restart the pipeline. If you would like
         to keep the images, see the :guilabel:`Remove Containers` tab.

   .. tab:: Remove Containers
      :tabid: remove-containers-and-images

      The following command removes the Docker containers, but not the Docker images,
      related to the sample pipeline:
      
      .. code-block:: shell
      
         docker-compose -p quickstart down

      .. important:: Docker Images Consume {+pipeline-size+} of Space
      
         The sample pipeline consumes {+pipeline-size+}
         of space in your development environment. You can free this space by
         removing the images related to the sample pipeline by following the steps
         in the :guilabel:`Remove Containers and Images` tab.

Next Steps
----------

To learn how to install the connector, see the
:ref:`<kafka-installation>` guide.

To learn more about moving data from {+ak+} to MongoDB, see the
:doc:`{+mkc+} Sink Connector <sink-connector>` guide. 

To learn more about moving data from MongoDB to {+ak+}, see the
:doc:`{+mkc+} Source Connector <source-connector>` guide.
