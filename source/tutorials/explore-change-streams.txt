.. _kafka-tutorial-explore-change-streams:

==============================
Explore MongoDB Change Streams 
==============================

Follow this tutorial to learn how to create a change stream on a MongoDB
collection and observe the change events it creates.

If you already understand how to create change streams and the change
event data they create, proceed to the 
(TODO: link ``Sourcing Data from MongoDB``) tutorial.

.. procedure::
   :style: connected

   .. step:: Connect to the Docker Container

      Create two interactive shell sessions on the tutorial Docker
      Container, each in a separate window.

      .. code-block:: bash

         docker run --rm --name shell1 --network mongodb-kafka-base_localnet -it robwma/mongokafkatutorial:latest bash

      .. code-block:: bash

         docker run --rm --name shell2 --network mongodb-kafka-base_localnet -it robwma/mongokafkatutorial:latest bash


   .. step:: Open a Change Stream


      TODO: could this be downloaded instead?
      .. code-block:: bash

         nano openchangestream.py
      
         
      .. code-block:: python

         import os
         import pymongo
         from bson.json_util import dumps
        
         client = pymongo.MongoClient('mongodb://mongo1')
         db = client.get_database(name='Tutorial1')
         with db.orders.watch() as stream:
             print('\nChange Stream is opened on the Tutorial1.orders namespace.  Currently watching ...\n\n')
             for change in stream:
                 print(dumps(change, indent=2))

      .. code-block:: bash

         python3 openchangestream.py
      

   .. step:: Trigger a Change Event

      .. code-block:: bash
         
         mongosh "mongodb://mongo1"


      .. code-block:: javascript

         use Tutorial1
         db.orders.insertOne( { 'test' : 1 } )

      .. code-block:: json
         :emphasize-lines: 5
         
         {
           "_id": {
             "_data": "8262648461000000012B022C0100296E5A1004A137DF2952414F6FB43DAA01CE8D54AB46645F6964006462648461D9440C0C72A2202C0004"
           },
           "operationType": "insert",
           "clusterTime": {
             "$timestamp": {
               "t": 1650754657,
               "i": 1
             }
           },
           "fullDocument": {
             "_id": {
               "$oid": "62648461d9440c0c72a2202c"
             },
             "test": 1
           },
           "ns": {
             "db": "Tutorial1",
             "coll": "orders"
           },
           "documentKey": {
             "_id": {
               "$oid": "62648461d9440c0c72a2202c"
             }
           }
         }


   .. step:: Open a Filtered Change Stream

      .. code-block:: bash

         nano pipeline.py

      .. code-block:: python

         import os
         import pymongo
         from bson.json_util import dumps
         client = pymongo.MongoClient('mongodb://mongo1')
         db = client.get_database(name='Tutorial1')
         pipeline = [{"$match":{ "$and": [{"fullDocument.type":"temp"},{"fullDocument.value":{"$gte":100}}] }}]
         with db.sensors.watch(pipeline=pipeline) as stream:
             print('\nChange Stream is opened on the Tutorial1.sensors namespace.  Currently watching for values > 100...\n\n')
             for change in stream:
                 print(dumps(change, indent=2))


      .. code-block:: python

         python3 pipeline.py


   .. step:: Observe the Filtered Change Stream

      .. code-block:: javascript

         use Tutorial1
         db.sensors.insertOne( { 'type' : 'temp', 'value':101 } )
      
      .. code-block:: json

         [{"$match":{ "$and": [{"fullDocument.type":"temp"},{"fullDocument.value":{"$gte":100}}] }}]

      .. code-block:: javascript

         db.sensors.insertOne( { 'type' : 'temp', 'value':99 } )
         db.sensors.insertOne( { 'type' : 'pressure', 'value':22 } )



Learn More
----------

:ref:`Change Streams and the Source Connector <kafka-source-change-streams>`



